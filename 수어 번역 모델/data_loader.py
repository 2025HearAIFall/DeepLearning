# data_loader.py (ìˆ˜ì •)

import os
import json
import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset
import time

class SignLanguageDataset(Dataset):
    # ðŸ’¡ [ìˆ˜ì •] index_file_path ëŒ€ì‹  data_frameì„ ë°›ë„ë¡ ë³€ê²½
    def __init__(self, data_frame, max_len=30, label_maps=None):
        self.max_len = max_len
        # ðŸ’¡ [ìˆ˜ì •] CSVë¥¼ ì½ëŠ” ëŒ€ì‹ , ì „ë‹¬ë°›ì€ DataFrameì„ ë°”ë¡œ ì‚¬ìš©
        self.data_info = data_frame

        if label_maps is None:
            self.labels = sorted(self.data_info['label'].unique())
            self.label_to_idx = {label: i for i, label in enumerate(self.labels)}
        else:
            self.labels = sorted(label_maps['label_to_idx'].keys())
            self.label_to_idx = label_maps['label_to_idx']
    
    def _reshape_and_get_xy(self, keypoints_data, expected_points):
        """í‚¤í¬ì¸íŠ¸ ë°ì´í„°ë¥¼ (N, 3)ìœ¼ë¡œ ë³€í™˜í•˜ê³  x, y ì¢Œí‘œë§Œ ì¶”ì¶œ, ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€"""
        keypoints = np.array(keypoints_data).flatten()
        if keypoints.size == 0:
            return np.zeros((expected_points, 2), dtype=np.float32)
        
        keypoints = keypoints.reshape(-1, 3)
        # ðŸ’¡ ì‹ ë¢°ë„(confidence)ë¥¼ ì œì™¸í•˜ê³  x, y ì¢Œí‘œë§Œ ì‚¬ìš©
        return keypoints[:, :2]

    def _extract_and_normalize_keypoints(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ðŸ’¡ [ìˆ˜ì •] people ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        #    (JSON êµ¬ì¡°ì— ë”°ë¼ person_data = data.get('people', [{}])[0]
        #     ë˜ëŠ” data.get('people', {}) ì‚¬ìš©. ì œê³µëœ JSON ê¸°ì¤€ìœ¼ë¡œëŠ” í›„ìžê°€ ë§žìŠµë‹ˆë‹¤.)
        person_data = data.get('people', {})

        # ðŸ’¡ [ìˆ˜ì •] Pose(ìƒì²´), Face, Hands í‚¤í¬ì¸íŠ¸ë¥¼ ëª¨ë‘ ì¶”ì¶œ (ê° 2D ì¢Œí‘œ)
        # OpenPose í‘œì¤€: Pose=25, Face=70, Hand=21
        pose_xy = self._reshape_and_get_xy(
            person_data.get('pose_keypoints_2d', []), 25)
        face_xy = self._reshape_and_get_xy(
            person_data.get('face_keypoints_2d', []), 70)
        left_hand_xy = self._reshape_and_get_xy(
            person_data.get('hand_left_keypoints_2d', []), 21)
        right_hand_xy = self._reshape_and_get_xy(
            person_data.get('hand_right_keypoints_2d', []), 21)

        # 1. ì¤‘ì‹¬ì  ì´ë™ (ëª© 'Neck' ê¸°ì¤€)
        # ðŸ’¡ [ìˆ˜ì •] Pose keypoint 1ë²ˆ(Neck)ì„ ì¤‘ì‹¬ì ìœ¼ë¡œ ì‚¬ìš©
        neck = pose_xy[1].copy()
        
        if np.sum(neck**2) > 1e-6: # ëª© ì¢Œí‘œê°€ (0,0)ì´ ì•„ë‹ ê²½ìš°
            pose_xy -= neck
            face_xy -= neck
            left_hand_xy -= neck
            right_hand_xy -= neck
        
        # ðŸ’¡ 2. í¬ê¸° ì •ê·œí™” (ëª¨ë“  ì¢Œí‘œ í†µí•©)
        combined_coords = np.vstack([pose_xy, face_xy, left_hand_xy, right_hand_xy])
        max_abs_val = np.max(np.abs(combined_coords))
        
        if max_abs_val > 1e-6:
            pose_xy /= max_abs_val
            face_xy /= max_abs_val
            left_hand_xy /= max_abs_val
            right_hand_xy /= max_abs_val

        # ðŸ’¡ [ìˆ˜ì •] ëª¨ë“  ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ê²°í•©
        # (50 + 140 + 42 + 42) = 274
        return np.concatenate([
            pose_xy.flatten(), 
            face_xy.flatten(), 
            left_hand_xy.flatten(), 
            right_hand_xy.flatten()
        ])

    def __len__(self):
        return len(self.data_info)

    def __getitem__(self, idx):
        item = self.data_info.iloc[idx]
        label = item['label']
        paths_str = item['file_paths']
        json_paths = paths_str.split(';')
        
        num_frames = len(json_paths)
        if num_frames > self.max_len:
            indices = np.linspace(0, num_frames - 1, self.max_len, dtype=int)
            sampled_paths = [json_paths[i] for i in indices]
        else:
            sampled_paths = json_paths

        sequence = []
        for path in sampled_paths:
            try:
                keypoints = self._extract_and_normalize_keypoints(path)
                sequence.append(keypoints)
            except Exception as e:
                continue
        
        # ðŸ’¡ [ìˆ˜ì •] ìž…ë ¥ í”¼ì²˜ í¬ê¸° ë³€ê²½ (274)
        num_features = 274
        
        if not sequence:
            # ðŸ’¡ [ìˆ˜ì •] ëª¨ì…˜ í”¼ì²˜ í¬í•¨ (274 * 2 = 548)
            sequence = np.zeros((self.max_len, num_features * 2), dtype=np.float32)
            label_idx = self.label_to_idx[label]
            return torch.from_numpy(sequence), torch.tensor(label_idx, dtype=torch.long)
            
        sequence = np.array(sequence, dtype=np.float32)
        
        positions = sequence
        motions = np.zeros_like(positions)
        if len(positions) > 1:
            motions[1:] = positions[1:] - positions[:-1]
        
        # ðŸ’¡ [ìˆ˜ì •] ìµœì¢… í”¼ì²˜: ìœ„ì¹˜(274) + ëª¨ì…˜(274) = 548
        final_sequence = np.concatenate([positions, motions], axis=1)

        seq_len = final_sequence.shape[0]
        if seq_len < self.max_len:
            padding = np.zeros((self.max_len - seq_len, final_sequence.shape[1]), dtype=np.float32)
            final_sequence = np.vstack([final_sequence, padding])

        label_idx = self.label_to_idx[label]
        return torch.from_numpy(final_sequence), torch.tensor(label_idx, dtype=torch.long)