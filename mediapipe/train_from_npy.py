# train_from_npy.py (Offline Augmentation ë²„ì „ìœ¼ë¡œ ê°œì¡°ë¨)
# -----------------------------------------------------------------------------
# [ëª©í‘œ]: 'all_index_npy.csv'ë¥¼ ì½ì–´ë“¤ì¸ ì§í›„,
#         ë©”ëª¨ë¦¬ ìƒì—ì„œ ë°ì´í„°ë¥¼ 30ë°°ë¡œ ì¦ê°•ì‹œí‚¤ê³ ,
#         30ë°°ê°€ ëœ ë°ì´í„°ë¡œ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤.
# -----------------------------------------------------------------------------

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
import pandas as pd
import numpy as np
import math
from collections import Counter
import pickle
import os 
import random 

# --- [ì‚¬ìš©ì ì„¤ì •] ---
INPUT_INDEX_FILE = 'all_index_npy.csv'
AUGMENTATION_FACTOR = 30 # 30ë°° ì¦ê°•
# ------------------------

# --- í•˜ì´í¼íŒŒë¼ë¯¸í„° (ì „ì—­ ë³€ìˆ˜ë¡œ ì´ë™) ---
MAX_LEN = 30
INPUT_SIZE = (33 + 468 + 21 + 21) * 2 * 2 # 2172

# --- í† í¬ë‚˜ì´ì € ë° Vocabulary í´ë˜ìŠ¤ ì •ì˜ ---
# ... (ì´ì „ê³¼ ë™ì¼) ...
def simple_tokenizer(text):
    return text.split(' ')

class Vocabulary:
    def __init__(self, tokenizer, min_freq=2):
        self.tokenizer = tokenizer
        self.itos = {0: "<PAD>", 1: "<SOS>", 2: "<EOS>", 3: "<UNK>"}
        self.stoi = {v: k for k, v in self.itos.items()}
        self.min_freq = min_freq
    def __len__(self): return len(self.itos)
    def build_vocab(self, sentence_list):
        counter = Counter()
        for sentence in sentence_list: counter.update(self.tokenizer(sentence))
        idx = 4 
        for word, freq in counter.items():
            if freq >= self.min_freq: self.stoi[word] = idx; self.itos[idx] = word; idx += 1
    def numericalize(self, text):
        tokens = self.tokenizer(text)
        return [self.stoi.get(token, self.stoi["<UNK>"]) for token in tokens]
    @property
    def pad_idx(self): return self.stoi["<PAD>"]
    @property
    def sos_idx(self): return self.stoi["<SOS>"]
    @property
    def eos_idx(self): return self.stoi["<EOS>"]
    @property
    def unk_idx(self): return self.stoi["<UNK>"]

# --------------------------------------------------
# [ê°œì¡°] NPY -> InMemory ë°ì´í„°ì…‹ í´ë˜ìŠ¤
# --------------------------------------------------
class SignLanguageDataset_InMemory(Dataset):
    def __init__(self, data_list, max_target_len=50, vocab=None):
        self.max_target_len = max_target_len
        # [ê°œì¡°] CSVê°€ ì•„ë‹Œ, (np.array, "ë¬¸ì¥") íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë°›ìŒ
        self.data_list = data_list 
        if vocab is None:
            raise ValueError("Vocabulary ê°ì²´ê°€ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        self.vocab = vocab
        
        # [ì œê±°ë¨] is_train (ì‹¤ì‹œê°„ ì¦ê°• ì•ˆ í•¨)

    def __len__(self):
        # [ê°œì¡°] data_infoê°€ ì•„ë‹Œ data_listì˜ ê¸¸ì´ ë°˜í™˜
        return len(self.data_list)
    
    def __getitem__(self, idx):
        # [ê°œì¡°] CSVê°€ ì•„ë‹Œ ë¦¬ìŠ¤íŠ¸ì—ì„œ (í…ì„œ, ë¬¸ì¥)ì„ ë°”ë¡œ ê°€ì ¸ì˜´
        final_sequence, sentence_str = self.data_list[idx]

        # íƒ€ê²Ÿ ë¬¸ì¥ ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        indices = self.vocab.numericalize(sentence_str)
        indices = [self.vocab.sos_idx] + indices + [self.vocab.eos_idx]
        if len(indices) < self.max_target_len:
            indices = indices + [self.vocab.pad_idx] * (self.max_target_len - len(indices))
        else:
            indices = indices[:self.max_target_len]
        target_tensor = torch.tensor(indices, dtype=torch.long)

        return torch.from_numpy(final_sequence), target_tensor

# --- [ê°œì¡°] ì¦ê°• í•¨ìˆ˜ (í´ë˜ìŠ¤ ë°–ìœ¼ë¡œ ì´ë™) ---
def augment_noise(keypoints_seq):
    """í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤ì— ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ(Jitter)ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    noise = np.random.normal(0, 0.005, keypoints_seq.shape).astype(np.float32)
    augmented_seq = keypoints_seq + noise
    return augmented_seq

# --------------------------------------------------
# [ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜] (Encoder, Attention, Decoder, Seq2Seq)
# ... (ì´ì „ê³¼ ë™ì¼) ...
class Encoder(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout_prob):
        super(Encoder, self).__init__()
        self.hidden_size = hidden_size; self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)
        self.dropout = nn.Dropout(dropout_prob)
    def forward(self, x):
        outputs, (hidden, cell) = self.lstm(x)
        return outputs, hidden, cell
class Attention(nn.Module):
    def __init__(self, hidden_size):
        super(Attention, self).__init__()
        self.attn = nn.Linear(hidden_size * 2, hidden_size)
        self.v = nn.Linear(hidden_size, 1, bias=False)
    def forward(self, hidden, encoder_outputs):
        seq_len = encoder_outputs.shape[1]
        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)
        energy_input = torch.cat((hidden, encoder_outputs), dim=2)
        energy = torch.tanh(self.attn(energy_input))
        attention_scores = self.v(energy)
        return torch.softmax(attention_scores.squeeze(2), dim=1).unsqueeze(1)
class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hidden_size, num_layers, dropout_prob):
        super(Decoder, self).__init__()
        self.output_dim = output_dim; self.hidden_size = hidden_size; self.num_layers = num_layers
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.attention = Attention(hidden_size)
        self.lstm = nn.LSTM(hidden_size + emb_dim, hidden_size, num_layers, dropout=dropout_prob)
        self.fc_out = nn.Linear(hidden_size * 2 + emb_dim, output_dim)
        self.dropout = nn.Dropout(dropout_prob)
    def forward(self, input_token, hidden, cell, encoder_outputs):
        input_token = input_token.unsqueeze(0)
        embedded = self.dropout(self.embedding(input_token))
        last_layer_hidden = hidden[-1]
        attn_weights = self.attention(last_layer_hidden, encoder_outputs)
        context = torch.bmm(attn_weights, encoder_outputs)
        context = context.permute(1, 0, 2)
        lstm_input = torch.cat((embedded, context), dim=2)
        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))
        prediction_input = torch.cat((output.squeeze(0), embedded.squeeze(0), context.squeeze(0)), dim=1)
        prediction = self.fc_out(prediction_input)
        return prediction, hidden, cell
class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        super(Seq2Seq, self).__init__()
        self.encoder = encoder; self.decoder = decoder; self.device = device
    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        batch_size = trg.shape[0]; trg_len = trg.shape[1]
        trg_vocab_size = self.decoder.output_dim
        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)
        encoder_outputs, hidden, cell = self.encoder(src)
        input_token = trg[:, 0]
        for t in range(1, trg_len):
            output, hidden, cell = self.decoder(input_token, hidden, cell, encoder_outputs)
            outputs[:, t, :] = output
            teacher_force = torch.rand(1) < teacher_forcing_ratio
            top1 = output.argmax(1)
            input_token = trg[:, t] if teacher_force else top1
        return outputs
# --------------------------------------------------
# ë©”ì¸ í•™ìŠµ ë¸”ë¡
# --------------------------------------------------

if __name__ == '__main__':
    
    # --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ---
    # ... (ì´ì „ê³¼ ë™ì¼) ...
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    BATCH_SIZE = 32
    LEARNING_RATE = 0.0005  
    NUM_EPOCHS = 30 
    MAX_TARGET_LEN = 50
    HIDDEN_SIZE = 512
    NUM_LAYERS = 3
    EMBED_SIZE = 256
    DROPOUT_PROB = 0.6
    NUM_WORKERS = 0 
    PATIENCE = 10 

    # --- [ê°œì¡°] ë°ì´í„° ì¤€ë¹„ ë° Vocabulary ìƒì„± ---
    print(f"'{INPUT_INDEX_FILE}' ë¡œë”© ë° Vocabulary ìƒì„± (NPYìš©)...")
    try:
        all_df = pd.read_csv(INPUT_INDEX_FILE)
    except FileNotFoundError:
        print(f"[ì˜¤ë¥˜] '{INPUT_INDEX_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    all_sentences = all_df['sentence'].tolist()

    vocab = Vocabulary(simple_tokenizer, min_freq=2)
    vocab.build_vocab(all_sentences)
    TARGET_VOCAB_SIZE = len(vocab)
    PAD_IDX = vocab.pad_idx

    print(f"ìƒì„±ëœ Target Vocabulary í¬ê¸°: {TARGET_VOCAB_SIZE}")
    print(f"ì›ë³¸ ë°ì´í„° ìˆ˜: {len(all_df)}ê°œ")

    # --- [ì‹ ê·œ] ì˜¤í”„ë¼ì¸(ë©”ëª¨ë¦¬) ì¦ê°• ---
    print(f"{AUGMENTATION_FACTOR}ë°° ì˜¤í”„ë¼ì¸ ì¦ê°•ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ë©”ëª¨ë¦¬ë¡œ ë¡œë“œ ì¤‘)")
    
    augmented_data_list = []
    
    for _, row in tqdm(all_df.iterrows(), total=len(all_df), desc="Augmenting"):
        npy_path = row['npy_path']
        sentence = row['sentence']
        
        try:
            original_sequence = np.load(npy_path)
        except Exception as e:
            print(f"Warning: Cannot load npy file {npy_path}. Skipping. Error: {e}")
            continue
            
        # 1. ì›ë³¸ 1ê°œ ì¶”ê°€
        augmented_data_list.append((original_sequence, sentence))
        
        # 2. (AUGMENTATION_FACTOR - 1) ë§Œí¼ ì¦ê°•í•˜ì—¬ ì¶”ê°€
        for _ in range(AUGMENTATION_FACTOR - 1):
            augmented_sequence = augment_noise(original_sequence)
            augmented_data_list.append((augmented_sequence, sentence))

    print(f"ì¦ê°• ì™„ë£Œ. ì´ ë°ì´í„° ìˆ˜: {len(augmented_data_list)}ê°œ")
    print("í†µí•© ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„í•  (In-Memory)...")

    try:
        # [ê°œì¡°] InMemory ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì‚¬ìš©
        full_dataset = SignLanguageDataset_InMemory(
            data_list=augmented_data_list, 
            max_target_len=MAX_TARGET_LEN,
            vocab=vocab
        )
    except Exception as e:
        print(f"ë°ì´í„°ì…‹ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()

    # (ë°ì´í„° ë¶„í•  ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    total_size = len(full_dataset) # 1560 (10ë°°)
    train_size = int(total_size * 0.8) # ì•½ 1248
    valid_size = int(total_size * 0.1) # ì•½ 156
    test_size = total_size - train_size - valid_size # ì•½ 156

    generator = torch.Generator().manual_seed(42)
    train_dataset, valid_dataset, test_dataset = random_split(
        full_dataset, [train_size, valid_size, test_size], generator=generator
    )

    print(f"ì´ ë°ì´í„°: {total_size}ê°œ")
    print(f"ë¶„ë¦¬ëœ í•™ìŠµ ë°ì´í„° ìˆ˜: {len(train_dataset)} ({train_size})")
    print(f"ë¶„ë¦¬ëœ ê²€ì¦ ë°ì´í„° ìˆ˜: {len(valid_dataset)} ({valid_size})")
    print(f"ë¶„ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜: {len(test_dataset)} ({test_size})")

    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

    # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì˜ ---
    # ... (ì´ì „ê³¼ ë™ì¼) ...
    encoder = Encoder(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT_PROB)
    decoder = Decoder(TARGET_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT_PROB)
    model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)
    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)
    best_val_loss = float('inf')
    patience_counter = 0
    best_model_path = 'model_a_mediapipe_best.pth'

    # --- ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---
    print(f"\nSeq2Seq (Offline Augmented NPY) ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (DEVICE: {DEVICE})")
    print(f"Epoch ë‹¹ ë°°ì¹˜ ìˆ˜: {len(train_loader)} (ì´ì „ 4/4ì—ì„œ ì¦ê°€ í™•ì¸)")
    
    for epoch in range(NUM_EPOCHS):
        model.train()
        train_loss = 0.0
        
        # (í•™ìŠµ ë£¨í”„ëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
        for (keypoints, targets) in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Training]"):
            keypoints, targets = keypoints.to(DEVICE), targets.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(keypoints, targets, teacher_forcing_ratio=0.5)
            output_dim = outputs.shape[-1]
            outputs_flat = outputs[:, 1:, :].reshape(-1, output_dim)
            targets_flat = targets[:, 1:].reshape(-1)
            loss = criterion(outputs_flat, targets_flat)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            train_loss += loss.item()

        # --- ê²€ì¦ ---
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for (keypoints, targets) in tqdm(valid_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Validation]"):
                keypoints, targets = keypoints.to(DEVICE), targets.to(DEVICE)
                outputs = model(keypoints, targets, teacher_forcing_ratio=0.0)
                output_dim = outputs.shape[-1]
                outputs_flat = outputs[:, 1:, :].reshape(-1, output_dim)
                targets_flat = targets[:, 1:].reshape(-1)
                loss = criterion(outputs_flat, targets_flat)
                val_loss += loss.item()

        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(valid_loader)
        
        try:
            train_ppl = math.exp(avg_train_loss)
            val_ppl = math.exp(avg_val_loss)
        except OverflowError:
            train_ppl = float('inf'); val_ppl = float('inf')

        print(f"Epoch [{epoch+1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.4f} (PPL: {train_ppl:.2f}), Val Loss: {avg_val_loss:.4f} (PPL: {val_ppl:.2f})")
        
        scheduler.step(avg_val_loss)

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ‰ New best model saved with Val Loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
            print(f"Patience: {patience_counter}/{PATIENCE}")
        
        if patience_counter >= PATIENCE:
            print(f"Early stopping triggered after {epoch+1} epochs.")
            break

    print("\ní•™ìŠµ ì™„ë£Œ!")

    # --- ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ---
    print(f"\nìµœê³  ì„±ëŠ¥ì˜ ëª¨ë¸({best_model_path})ì„ ë¡œë“œí•˜ì—¬ ìµœì¢… í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
    try:
        model.load_state_dict(torch.load(best_model_path))
    except Exception as e:
        print(f"[ê²½ê³ ] ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ë§ˆì§€ë§‰ epochì˜ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        
    model.eval()
    test_loss = 0.0
    with torch.no_grad():
        for (keypoints, targets) in tqdm(test_loader, desc="Final Test"):
            keypoints, targets = keypoints.to(DEVICE), targets.to(DEVICE)
            outputs = model(keypoints, targets, teacher_forcing_ratio=0.0)
            output_dim = outputs.shape[-1]
            outputs_flat = outputs[:, 1:, :].reshape(-1, output_dim)
            targets_flat = targets[:, 1:].reshape(-1)
            loss = criterion(outputs_flat, targets_flat)
            test_loss += loss.item()

    avg_test_loss = test_loss / len(test_loader)
    try: test_ppl = math.exp(avg_test_loss)
    except OverflowError: test_ppl = float('inf')
        
    print(f"\nìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤ (Test Loss): {avg_test_loss:.4f}, í…ŒìŠ¤íŠ¸ Perplexity (PPL): {test_ppl:.2f}")

    print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì´ '{best_model_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    with open('vocab.pkl', 'wb') as f:
        pickle.dump(vocab, f)
    print("Vocabularyê°€ 'vocab.pkl' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
