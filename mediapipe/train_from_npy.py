# train_from_npy.py
# -----------------------------------------------------------------------------
# [ëª©í‘œ]: 'all_index_npy.csv' íŒŒì¼ í•˜ë‚˜ë¥¼ ì…ë ¥ë°›ì•„
#         í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ìë™ ë¶„í• í•˜ì—¬ ë¹ ë¥¸ í›ˆë ¨ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
#
# [ì£¼ìš” ë³€ê²½ì ]
# 1. (ë°ì´í„°) 'SignLanguageDataset_NPY' (.npy ë¡œë“œ) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
# 2. (ê²½ë¡œ) 'all_index_npy.csv' íŒŒì¼ í•˜ë‚˜ë§Œ ì§ì ‘ ì½ì–´ë“¤ì…ë‹ˆë‹¤.
# 3. (ë¶„í• ) ì½ì–´ë“¤ì¸ ì „ì²´ ë°ì´í„°ë¥¼ 80/10/10 ë¹„ìœ¨ë¡œ ìë™ ë¶„í• í•©ë‹ˆë‹¤.
# -----------------------------------------------------------------------------

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
import pandas as pd
import numpy as np
import math
from collections import Counter
import pickle
import os 

# --- [ì‚¬ìš©ì ì„¤ì •] ---
# preprocess_to_npy.pyë¡œ ìƒì„±ëœ í†µí•© ì¸ë±ìŠ¤ íŒŒì¼
INPUT_INDEX_FILE = 'all_index_npy.csv'
# ------------------------

# --- í† í¬ë‚˜ì´ì € ë° Vocabulary í´ë˜ìŠ¤ ì •ì˜ ---
def simple_tokenizer(text):
    return text.split(' ')

class Vocabulary:
    def __init__(self, tokenizer, min_freq=2):
        self.tokenizer = tokenizer
        self.itos = {0: "<PAD>", 1: "<SOS>", 2: "<EOS>", 3: "<UNK>"}
        self.stoi = {v: k for k, v in self.itos.items()}
        self.min_freq = min_freq
        
    def __len__(self):
        return len(self.itos)
    
    def build_vocab(self, sentence_list):
        counter = Counter()
        for sentence in sentence_list:
            counter.update(self.tokenizer(sentence))
        idx = 4 
        for word, freq in counter.items():
            if freq >= self.min_freq:
                self.stoi[word] = idx
                self.itos[idx] = word
                idx += 1
                
    def numericalize(self, text):
        tokens = self.tokenizer(text)
        return [self.stoi.get(token, self.stoi["<UNK>"]) for token in tokens]
    
    @property
    def pad_idx(self): return self.stoi["<PAD>"]
    @property
    def sos_idx(self): return self.stoi["<SOS>"]
    @property
    def eos_idx(self): return self.stoi["<EOS>"]
    @property
    def unk_idx(self): return self.stoi["<UNK>"]

# --------------------------------------------------
# [NPY ì „ìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤]
# --------------------------------------------------
class SignLanguageDataset_NPY(Dataset):
    def __init__(self, index_file_path, max_target_len=50, vocab=None):
        self.max_target_len = max_target_len
        # "npy_path,sentence" í˜•ì‹ì˜ CSV ë¡œë“œ
        self.data_info = pd.read_csv(index_file_path) 
        if vocab is None:
            raise ValueError("Vocabulary ê°ì²´ê°€ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        self.vocab = vocab

    def __len__(self):
        return len(self.data_info)

    def __getitem__(self, idx):
        item = self.data_info.iloc[idx]
        sentence_str = item['sentence']
        npy_path = item['npy_path']
        
        try:
            # .npy íŒŒì¼ì„ ë¡œë“œ (ì´ê²ƒì´ (30, 2172) í…ì„œì„)
            final_sequence = np.load(npy_path) 
        except Exception as e:
            print(f"Warning: Cannot load npy file {npy_path}. Error: {e}")
            final_sequence = np.zeros((MAX_LEN, INPUT_SIZE), dtype=np.float32)

        # íƒ€ê²Ÿ ë¬¸ì¥ ì²˜ë¦¬
        indices = self.vocab.numericalize(sentence_str)
        indices = [self.vocab.sos_idx] + indices + [self.vocab.eos_idx]
        if len(indices) < self.max_target_len:
            indices = indices + [self.vocab.pad_idx] * (self.max_target_len - len(indices))
        else:
            indices = indices[:self.max_target_len]
        target_tensor = torch.tensor(indices, dtype=torch.long)

        return torch.from_numpy(final_sequence), target_tensor

# --------------------------------------------------
# [ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜] (Encoder, Attention, Decoder, Seq2Seq)
# --------------------------------------------------

class Encoder(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout_prob):
        super(Encoder, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)
        self.dropout = nn.Dropout(dropout_prob)
    def forward(self, x):
        outputs, (hidden, cell) = self.lstm(x)
        return outputs, hidden, cell

class Attention(nn.Module):
    def __init__(self, hidden_size):
        super(Attention, self).__init__()
        self.attn = nn.Linear(hidden_size * 2, hidden_size)
        self.v = nn.Linear(hidden_size, 1, bias=False)
    def forward(self, hidden, encoder_outputs):
        seq_len = encoder_outputs.shape[1]
        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)
        energy_input = torch.cat((hidden, encoder_outputs), dim=2)
        energy = torch.tanh(self.attn(energy_input))
        attention_scores = self.v(energy)
        return torch.softmax(attention_scores.squeeze(2), dim=1).unsqueeze(1)

class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hidden_size, num_layers, dropout_prob):
        super(Decoder, self).__init__()
        self.output_dim = output_dim
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.attention = Attention(hidden_size)
        self.lstm = nn.LSTM(hidden_size + emb_dim, hidden_size, num_layers, dropout=dropout_prob)
        self.fc_out = nn.Linear(hidden_size * 2 + emb_dim, output_dim)
        self.dropout = nn.Dropout(dropout_prob)
    def forward(self, input_token, hidden, cell, encoder_outputs):
        input_token = input_token.unsqueeze(0)
        embedded = self.dropout(self.embedding(input_token))
        last_layer_hidden = hidden[-1]
        attn_weights = self.attention(last_layer_hidden, encoder_outputs)
        context = torch.bmm(attn_weights, encoder_outputs)
        context = context.permute(1, 0, 2)
        lstm_input = torch.cat((embedded, context), dim=2)
        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))
        prediction_input = torch.cat((output.squeeze(0), embedded.squeeze(0), context.squeeze(0)), dim=1)
        prediction = self.fc_out(prediction_input)
        return prediction, hidden, cell

class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        super(Seq2Seq, self).__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.device = device
    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        batch_size = trg.shape[0]; trg_len = trg.shape[1]
        trg_vocab_size = self.decoder.output_dim
        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)
        encoder_outputs, hidden, cell = self.encoder(src)
        input_token = trg[:, 0]
        for t in range(1, trg_len):
            output, hidden, cell = self.decoder(input_token, hidden, cell, encoder_outputs)
            outputs[:, t, :] = output
            teacher_force = torch.rand(1) < teacher_forcing_ratio
            top1 = output.argmax(1)
            input_token = trg[:, t] if teacher_force else top1
        return outputs

# --------------------------------------------------
# ë©”ì¸ í•™ìŠµ ë¸”ë¡
# --------------------------------------------------

if __name__ == '__main__':
    
    # --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ---
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    BATCH_SIZE = 32
    LEARNING_RATE = 0.0005  
    NUM_EPOCHS = 100 # ì†ë„ê°€ ë¹ ë¥´ë‹ˆ Epochë¥¼ 100 ì •ë„ë¡œ ëŠ˜ë ¤ì„œ ì¶©ë¶„íˆ í•™ìŠµ
    MAX_LEN = 30
    MAX_TARGET_LEN = 50
    
    # NPY íŒŒì¼ê³¼ ë™ì¼í•œ INPUT_SIZE (2172)
    INPUT_SIZE = (33 + 468 + 21 + 21) * 2 * 2 # 2172
    
    HIDDEN_SIZE = 512
    NUM_LAYERS = 3
    EMBED_SIZE = 256
    DROPOUT_PROB = 0.6
    NUM_WORKERS = 0 
    PATIENCE = 10 

    # --- [CHANGED] ë°ì´í„° ì¤€ë¹„ ë° Vocabulary ìƒì„± ---
    print(f"'{INPUT_INDEX_FILE}' ë¡œë”© ë° Vocabulary ìƒì„± (NPYìš©)...")
    try:
        # [CHANGED] all_index_npy.csv íŒŒì¼ì„ ì§ì ‘ ë¡œë“œ
        all_df = pd.read_csv(INPUT_INDEX_FILE)
    except FileNotFoundError:
        print(f"[ì˜¤ë¥˜] '{INPUT_INDEX_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(">>> 'preprocess_to_npy.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ê³ ,")
        print(">>> 'train_index_npy.csv'ì™€ 'valid_index_npy.csv'ë¥¼ 'all_index_npy.csv'ë¡œ ë³‘í•©í•´ì•¼ í•©ë‹ˆë‹¤.")
        exit()

    all_sentences = all_df['sentence'].tolist()

    vocab = Vocabulary(simple_tokenizer, min_freq=2)
    vocab.build_vocab(all_sentences)
    TARGET_VOCAB_SIZE = len(vocab)
    PAD_IDX = vocab.pad_idx

    print(f"ìƒì„±ëœ Target Vocabulary í¬ê¸°: {TARGET_VOCAB_SIZE}")

    print("í†µí•© ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„í•  (NPY)...")

    try:
        # [CHANGED] ìƒˆ ë°ì´í„°ì…‹ í´ë˜ìŠ¤(SignLanguageDataset_NPY) ì‚¬ìš©
        # index_file_pathì— all_index_npy.csv ê²½ë¡œë¥¼ ë°”ë¡œ ì „ë‹¬
        full_dataset = SignLanguageDataset_NPY(
            index_file_path=INPUT_INDEX_FILE, 
            max_target_len=MAX_TARGET_LEN,
            vocab=vocab
        )
    except Exception as e:
        print(f"ë°ì´í„°ì…‹ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()

    # (ë°ì´í„° ë¶„í•  ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    total_size = len(full_dataset)
    train_size = int(total_size * 0.8)
    valid_size = int(total_size * 0.1)
    test_size = total_size - train_size - valid_size 

    # [ì¤‘ìš”] test_sizeê°€ 0ì´ ë˜ì§€ ì•Šë„ë¡ ë³´ì • (ë°ì´í„°ê°€ ì ì„ ê²½ìš° ëŒ€ë¹„)
    if total_size < 10:
        print("[ê²½ê³ ] ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. í›ˆë ¨ì´ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    if valid_size == 0 and total_size > 10:
        valid_size = 1
    if test_size == 0 and total_size > 10:
        test_size = 1
    train_size = total_size - valid_size - test_size


    generator = torch.Generator().manual_seed(42)
    train_dataset, valid_dataset, test_dataset = random_split(
        full_dataset, [train_size, valid_size, test_size], generator=generator
    )

    print(f"ì´ ë°ì´í„°: {total_size}ê°œ")
    print(f"ë¶„ë¦¬ëœ í•™ìŠµ ë°ì´í„° ìˆ˜: {len(train_dataset)} ({train_size})")
    print(f"ë¶„ë¦¬ëœ ê²€ì¦ ë°ì´í„° ìˆ˜: {len(valid_dataset)} ({valid_size})")
    print(f"ë¶„ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜: {len(test_dataset)} ({test_size})")

    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

    # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì˜ ---
    encoder = Encoder(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT_PROB)
    decoder = Decoder(TARGET_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, DROPOUT_PROB)
    model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)

    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

    best_val_loss = float('inf')
    patience_counter = 0
    
    # (export_to_onnx.py í˜¸í™˜)
    best_model_path = 'model_a_mediapipe_best.pth'

    # --- ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---
    print(f"\nSeq2Seq (NPY) ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (DEVICE: {DEVICE})")
    for epoch in range(NUM_EPOCHS):
        model.train()
        train_loss = 0.0
        
        # (í•™ìŠµ ë£¨í”„ëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
        for (keypoints, targets) in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Training]"):
            keypoints, targets = keypoints.to(DEVICE), targets.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(keypoints, targets, teacher_forcing_ratio=0.5)
            output_dim = outputs.shape[-1]
            outputs_flat = outputs[:, 1:, :].reshape(-1, output_dim)
            targets_flat = targets[:, 1:].reshape(-1)
            loss = criterion(outputs_flat, targets_flat)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            train_loss += loss.item()

        # --- ê²€ì¦ ---
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            # (ê²€ì¦ ë£¨í”„ëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
            for (keypoints, targets) in tqdm(valid_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS} [Validation]"):
                keypoints, targets = keypoints.to(DEVICE), targets.to(DEVICE)
                outputs = model(keypoints, targets, teacher_forcing_ratio=0.0)
                output_dim = outputs.shape[-1]
                outputs_flat = outputs[:, 1:, :].reshape(-1, output_dim)
                targets_flat = targets[:, 1:].reshape(-1)
                loss = criterion(outputs_flat, targets_flat)
                val_loss += loss.item()

        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(valid_loader)
        
        try:
            train_ppl = math.exp(avg_train_loss)
            val_ppl = math.exp(avg_val_loss)
        except OverflowError:
            train_ppl = float('inf')
            val_ppl = float('inf')

        print(f"Epoch [{epoch+1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.4f} (PPL: {train_ppl:.2f}), Val Loss: {avg_val_loss:.4f} (PPL: {val_ppl:.2f})")
        
        scheduler.step(avg_val_loss)

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ‰ New best model saved with Val Loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
            print(f"Patience: {patience_counter}/{PATIENCE}")
        
        if patience_counter >= PATIENCE:
            print(f"Early stopping triggered after {epoch+1} epochs.")
            break

    print("\ní•™ìŠµ ì™„ë£Œ!")

    # --- ìµœì¢… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ---
    print(f"\nìµœê³  ì„±ëŠ¥ì˜ ëª¨ë¸({best_model_path})ì„ ë¡œë“œí•˜ì—¬ ìµœì¢… í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
    try:
        model.load_state_dict(torch.load(best_model_path))
    except FileNotFoundError:
        print(f"[ê²½ê³ ] {best_model_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ epochì˜ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"[ê²½ê³ ] ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ë§ˆì§€ë§‰ epochì˜ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        
    model.eval()
    test_loss = 0.0
    with torch.no_grad():
        # (í…ŒìŠ¤íŠ¸ ë£¨í”„ëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
        for (keypoints, targets) in tqdm(test_loader, desc="Final Test"):
            keypoints, targets = keypoints.to(DEVICE), targets.to(DEVICE)
            outputs = model(keypoints, targets, teacher_forcing_ratio=0.0)
            output_dim = outputs.shape[-1]
            outputs_flat = outputs[:, 1:, :].reshape(-1, output_dim)
            targets_flat = targets[:, 1:].reshape(-1)
            loss = criterion(outputs_flat, targets_flat)
            test_loss += loss.item()

    avg_test_loss = test_loss / len(test_loader)
    try:
        test_ppl = math.exp(avg_test_loss)
    except OverflowError:
        test_ppl = float('inf')
        
    print(f"\nìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤ (Test Loss): {avg_test_loss:.4f}, í…ŒìŠ¤íŠ¸ Perplexity (PPL): {test_ppl:.2f}")

    print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì´ '{best_model_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # (Vocab ì €ì¥ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    with open('vocab.pkl', 'wb') as f:
        pickle.dump(vocab, f)
    print("Vocabularyê°€ 'vocab.pkl' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")