# preprocess.py (ìˆ˜ì •: ë¬¸ì¥ ì¶”ì¶œ)

import os
import csv
from tqdm import tqdm
import re
from collections import defaultdict
import glob
import json

sets_to_process = {
    'training': './videos/1.Training',
    'validation': './videos/2.Validation'
}

def _build_label_map(root_dir):
    """
    Morpheme JSON íŒŒì¼ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬
    'base_name'ì„ í‚¤ë¡œ, 'ì™„ì„±ëœ ë¬¸ì¥'ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print(f"-> '{root_dir}'ì—ì„œ ë¼ë²¨(morpheme) íŒŒì¼ ìŠ¤ìº” ì¤‘...")
    search_pattern = os.path.join(root_dir, "**", "*_morpheme.json")
    
    morpheme_files_iter = glob.iglob(search_pattern, recursive=True)
    morpheme_files = list(tqdm(morpheme_files_iter, desc="[1/2] Morpheme íŒŒì¼ ì°¾ëŠ” ì¤‘"))
    
    label_map = {}
    skipped_files = 0
    
    for morpheme_path in tqdm(morpheme_files, desc="[2/2] Morpheme íŒŒì¼ ì²˜ë¦¬ ì¤‘"):
        try:
            base_name = os.path.basename(morpheme_path).replace('_morpheme.json', '')

            with open(morpheme_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            data_items = data.get('data')

            # ğŸ’¡ [í•µì‹¬ ë¡œì§ ìˆ˜ì •]
            # 'data' í‚¤ê°€ ë¦¬ìŠ¤íŠ¸ì´ê³ , í•­ëª©ì´ 1ê°œ ì´ìƒì¼ ë•Œ (ë¬¸ì¥)
            if isinstance(data_items, list) and len(data_items) > 0:
                words = []
                for item in data_items:
                    # ê° í˜•íƒœì†Œ ì •ë³´ì—ì„œ ë‹¨ì–´(name) ì¶”ì¶œ
                    item_attrs = item.get('attributes', [{}])[0]
                    word = item_attrs.get('name')
                    if word:
                        words.append(word)
                
                if not words: # ì¶”ì¶œëœ ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    skipped_files += 1
                    continue
                
                # ë‹¨ì–´ë“¤ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë¬¸ì¥ ìƒì„±
                final_sentence = " ".join(words)
                label_map[base_name] = final_sentence
                    
            else:
                # í•­ëª©ì´ ì—†ëŠ” ë“± ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°
                skipped_files += 1
        
        except Exception as e:
            skipped_files += 1
            pass # ì˜¤ë¥˜ê°€ ë‚˜ë„ ê³„ì† ì§„í–‰
    
    print(f"-> ì´ {len(morpheme_files)}ê°œ morpheme íŒŒì¼ ë°œê²¬.")
    print(f"-> {len(label_map)}ê°œì˜ ë¬¸ì¥ ë¼ë²¨ì„ ë§µí•‘í–ˆìŠµë‹ˆë‹¤. (ìœ íš¨í•˜ì§€ ì•Šì€ íŒŒì¼ {skipped_files}ê°œ ìŠ¤í‚µ)")
    return label_map

def create_index_file_optimized(dataset_name, root_dir):
    print(f"\n'{dataset_name}' ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ìƒì„± (íŒŒì¼ ê²½ë¡œ ìë™ íƒìƒ‰)...")
    
    output_filename = f'{dataset_name}_index.csv'
    
    if not os.path.isdir(root_dir):
        print(f"-> [âŒ ì˜¤ë¥˜] ìµœìƒìœ„ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {root_dir}")
        return

    # 1. ë¼ë²¨ ë§µ(ë¬¸ì¥) ìƒì„±
    label_map = _build_label_map(root_dir)
    if not label_map:
        print(f"-> [âŒ ì˜¤ë¥˜] '{root_dir}'ì—ì„œ ìœ íš¨í•œ (ë¬¸ì¥) morpheme íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"'{root_dir}' ê²½ë¡œ ë° ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ keypoint íŒŒì¼ì„ íƒìƒ‰í•©ë‹ˆë‹¤...")
    search_pattern = os.path.join(root_dir, "**", "*_keypoints.json")
    
    all_files_iter = glob.iglob(search_pattern, recursive=True)
    all_files = list(tqdm(all_files_iter, desc="[1/3] Keypoint íŒŒì¼ ì°¾ëŠ” ì¤‘"))
    
    if not all_files:
        print(f"-> [âŒ ì˜¤ë¥˜] '{root_dir}' ê²½ë¡œì—ì„œ Keypoint íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"âœ… ì´ {len(all_files)}ê°œì˜ keypoint íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì´ì œ ê·¸ë£¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    gesture_groups = defaultdict(list)
    for file_path in tqdm(sorted(all_files), desc="[2/3] Keypoint íŒŒì¼ ê·¸ë£¹í™”"):
        filename = os.path.basename(file_path)
        base_name = '_'.join(filename.split('_')[:-2])
        gesture_groups[base_name].append(file_path)

    total_groups_written = 0
    with open(output_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.writer(csvfile)
        # ğŸ’¡ [ìˆ˜ì •] 'label' -> 'sentence' (ëª…í™•í•œ ì´ë¦„)
        writer.writerow(['gesture_base_name', 'sentence', 'file_paths'])

        for base_name, file_list in tqdm(gesture_groups.items(), desc=f"[3/3] '{dataset_name}' CSV ìƒì„±"):
            
            # ğŸ’¡ [ìˆ˜ì •] ë¼ë²¨(ë¬¸ì¥) ê°€ì ¸ì˜¤ê¸°
            sentence = label_map.get(base_name)
            
            # ë¼ë²¨ ë§µì— ìˆëŠ” (ë¬¸ì¥) ë°ì´í„°ë§Œ CSVì— ì“´ë‹¤
            if sentence:
                paths_str = ";".join(file_list)
                writer.writerow([base_name, sentence, paths_str])
                total_groups_written += 1
    
    print(f"âœ… ì„±ê³µ! ì´ {len(gesture_groups)}ê°œ keypoint ê·¸ë£¹ ì¤‘ {total_groups_written}ê°œì˜ ìœ íš¨í•œ ë™ì‘ ê·¸ë£¹ê³¼ íŒŒì¼ ê²½ë¡œë¥¼ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


if __name__ == '__main__':
    for name, path in sets_to_process.items():
        create_index_file_optimized(name, path)